{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 300\n",
    "img_width = 200\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Przykładowe wartości\n",
    "])\n",
    "\n",
    "data_dir = './raw-img'  # Path to your dataset\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "classes = dataset.classes\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_data, val_data= random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, batch_size, kernel_size=11, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=batch_size, out_channels=64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=96, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # tutaj nie dawać dropout\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        n_channels = self.feature_extractor(torch.empty(1, 3, img_height, img_width)).size(-1)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=n_channels, out_features=1024, bias=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=n_channels, out_features=1024, bias=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(in_features=1024, out_features=len(classes), bias=1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "\n",
    "\n",
    "net = SimpleCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uczenie\n",
    "\n",
    "\n",
    "net.train()\n",
    "for epoch in range(1):  # liczba epok\n",
    "    loss_epoch = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for i, batch in enumerate(train_loader, 0):\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_epoch += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "        # print(f\"epoch {epoch}, batch = {i}, loss = {loss.item()}, inputs.shape = {inputs.shape}\")\n",
    "    print(f\"epoch = {epoch}, accuracy = {accuracy}, loss = {loss_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.1840727e-04 2.4415588e-04 8.3972716e-01 ... 3.1816293e-03\n",
      "  7.1498338e-04 6.6428341e-02]\n",
      " [5.7939583e-01 2.9078059e-02 2.5012193e-02 ... 3.7561566e-02\n",
      "  2.4268913e-01 3.7238125e-03]\n",
      " [3.0388923e-03 6.7567853e-03 3.1161809e-01 ... 2.1343412e-02\n",
      "  2.6483095e-01 9.2413835e-02]\n",
      " ...\n",
      " [1.7165463e-02 1.4238151e-02 7.9960957e-02 ... 5.3411812e-02\n",
      "  4.7253884e-02 7.3325986e-01]\n",
      " [1.2043575e-03 1.4729572e-02 2.1929260e-01 ... 3.0278873e-01\n",
      "  9.9355496e-02 1.1293743e-01]\n",
      " [2.9673523e-03 1.4596226e-02 1.3253026e-02 ... 1.4334393e-01\n",
      "  7.2955735e-02 3.6979888e-02]]\n",
      "[6 2 2 ... 2 7 2]\n",
      "(5236, 10)\n",
      "(5236,)\n"
     ]
    }
   ],
   "source": [
    "# testowanie\n",
    "net.eval()\n",
    "\n",
    "outputs_all = []\n",
    "labels_all = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images, labels = batch\n",
    "        outputs = net(images)\n",
    "        outputs_all.append(torch.softmax(outputs, dim=1).detach().cpu().numpy())\n",
    "        labels_all.append(labels.numpy())\n",
    "\n",
    "outputs_all = np.concatenate(outputs_all)\n",
    "labels_all = np.concatenate(labels_all)\n",
    "\n",
    "print(outputs_all)\n",
    "print(labels_all)\n",
    "\n",
    "print(outputs_all.shape)\n",
    "print(labels_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: squirrel\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image_path = './val_img/butterfly.jpg'\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():  # No gradient computation for inference\n",
    "    outputs = net(image_tensor)\n",
    "    _, predicted_class = torch.max(outputs, 1)  # Get the class index with the highest score\n",
    "\n",
    "\n",
    "predicted_label = classes[predicted_class.item()]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AUC = roc_auc_score(y_true=labels_all, y_score=outputs_all[:,1])\n",
    "print(f\"AUC = {AUC}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true=labels_all, y_score=outputs_all[:,1], pos_label=1)\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "\n",
    "y_d = np.argmax(outputs_all, axis=1)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=labels_all, y_pred=y_d).ravel()\n",
    "\n",
    "print(f\"tn {tn}, fp {fp}, fn {fn}, tp {tp}\")\n",
    "\n",
    "# _ = ConfusionMatrixDisplay.from_estimator(classifier_05, X_test, y_test)\n",
    "\n",
    "def get_label(x):\n",
    "    return ['benign' if z == 0 else 'malignant' for z in x]\n",
    "\n",
    "cm = confusion_matrix(y_true=get_label(labels_all), y_pred=get_label(y_d), labels=['benign','malignant'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['benign','malignant'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: butterfly is 63.6 %\n",
      "Accuracy for class: cat   is 20.1 %\n",
      "Accuracy for class: chicken is 61.0 %\n",
      "Accuracy for class: cow   is 26.8 %\n",
      "Accuracy for class: dog   is 45.6 %\n",
      "Accuracy for class: elephant is 37.8 %\n",
      "Accuracy for class: horse is 58.5 %\n",
      "Accuracy for class: sheep is 46.0 %\n",
      "Accuracy for class: spider is 85.2 %\n",
      "Accuracy for class: squirrel is 55.0 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
