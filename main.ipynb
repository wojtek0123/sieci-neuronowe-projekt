{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 300\n",
    "img_width = 200\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "['cane', 'cavallo', 'elefante', 'farfalla', 'gallina', 'gatto', 'mucca', 'pecora', 'ragno', 'scoiattolo']\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Przykładowe wartości\n",
    "])\n",
    "\n",
    "data_dir = './raw-img'  # Path to your dataset\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "classes = dataset.classes\n",
    "\n",
    "print(classes)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_data, val_data= random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, batch_size, kernel_size=5, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # tutaj nie dawać dropout\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        n_channels = self.feature_extractor(torch.empty(1, 3, img_height, img_width)).size(-1)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=n_channels, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=512, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=len(classes))\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "\n",
    "\n",
    "net = SimpleCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uczenie\n",
    "\n",
    "\n",
    "net.train()\n",
    "for epoch in range(10):  # liczba epok\n",
    "    loss_epoch = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for i, batch in enumerate(train_loader, 0):\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_epoch += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "        # print(f\"epoch {epoch}, batch = {i}, loss = {loss.item()}, inputs.shape = {inputs.shape}\")\n",
    "    print(f\"epoch = {epoch}, accuracy = {accuracy}, loss = {loss_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapisz model\n",
    "\n",
    "torch.save(net.state_dict(), './neural-network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=52992, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# załaduj wytrenowany model\n",
    "\n",
    "net = SimpleCNN()\n",
    "net.load_state_dict(torch.load('./cnn_20.pth', weights_only=True, map_location=torch.device('cpu')))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9897110e-01 7.4415773e-05 1.2439184e-05 ... 1.3125040e-06\n",
      "  3.4076001e-07 7.3896757e-07]\n",
      " [9.8935741e-01 2.0782067e-05 2.0576856e-06 ... 7.3342747e-03\n",
      "  3.5656881e-04 5.8953117e-07]\n",
      " [9.9979860e-01 1.2054069e-07 4.6015660e-11 ... 5.9563745e-09\n",
      "  4.9447449e-06 3.0852116e-11]\n",
      " ...\n",
      " [4.7624469e-01 1.3884458e-02 1.1914163e-01 ... 2.5841083e-02\n",
      "  3.1987999e-02 2.9390654e-01]\n",
      " [9.8871326e-01 8.9211063e-03 1.6895961e-03 ... 1.4293512e-05\n",
      "  1.4541167e-06 8.1865515e-08]\n",
      " [9.6717715e-01 4.7309627e-04 1.6334279e-03 ... 5.4824154e-04\n",
      "  7.9612837e-05 1.5120078e-03]]\n",
      "[0 0 0 ... 0 0 0]\n",
      "(5236, 10)\n",
      "(5236,)\n"
     ]
    }
   ],
   "source": [
    "# testowanie\n",
    "net.eval()\n",
    "\n",
    "outputs_all = []\n",
    "labels_all = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images, labels = batch\n",
    "        outputs = net(images)\n",
    "        outputs_all.append(torch.softmax(outputs, dim=1).detach().cpu().numpy())\n",
    "        labels_all.append(labels.numpy())\n",
    "\n",
    "outputs_all = np.concatenate(outputs_all)\n",
    "labels_all = np.concatenate(labels_all)\n",
    "\n",
    "print(outputs_all)\n",
    "print(labels_all)\n",
    "\n",
    "print(outputs_all.shape)\n",
    "print(labels_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: gatto\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image_path = './val_img/cat.jpg'\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():  # No gradient computation for inference\n",
    "    outputs = net(image_tensor)\n",
    "    _, predicted_class = torch.max(outputs, 1)  # Get the class index with the highest score\n",
    "\n",
    "\n",
    "predicted_label = classes[predicted_class.item()]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9904\n",
      "Accuracy = 0.9211\n",
      "Precision = 0.9252\n",
      "Recall = 0.9100\n",
      "F1 = 0.9171\n",
      "[894  11   5   6   9  13   5  10  14   4  20 455   3   0   7   1   8   3\n",
      "   1   1   8   4 251   1   2   0   5   1   3   2   5   2   2 424   6   1\n",
      "   0   0  21   2   7   3   1   3 577   0   2   0  11   3  17   1   1   2\n",
      "   2 308   1   1  17   5  10   8   4   0   4   2 325  14   2   2  13   5\n",
      "   3   1   2   2   4 325   7   3   2   1   1   5   6   1   1   2 939   2\n",
      "  15   1   0   4   3   1   0   1  18 325]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       971\n",
      "           1       0.93      0.91      0.92       499\n",
      "           2       0.93      0.91      0.92       277\n",
      "           3       0.95      0.92      0.93       463\n",
      "           4       0.93      0.95      0.94       607\n",
      "           5       0.94      0.87      0.90       355\n",
      "           6       0.93      0.88      0.90       371\n",
      "           7       0.91      0.89      0.90       365\n",
      "           8       0.91      0.98      0.94       960\n",
      "           9       0.93      0.88      0.91       368\n",
      "\n",
      "    accuracy                           0.92      5236\n",
      "   macro avg       0.93      0.91      0.92      5236\n",
      "weighted avg       0.92      0.92      0.92      5236\n",
      "\n",
      "AUC = 0.9904\n"
     ]
    }
   ],
   "source": [
    "\n",
    "AUC = roc_auc_score(np.eye(10)[labels_all], outputs_all, multi_class='ovo')\n",
    "print(f\"AUC = {AUC:.4f}\")\n",
    "\n",
    "#fpr, tpr, thresholds = roc_curve(y_true=labels_all, y_score=outputs_all, pos_label=1)\n",
    "#plt.plot(fpr, tpr)\n",
    "\n",
    "\n",
    "predictions = np.argmax(outputs_all, axis=1)\n",
    "#tn, fp, fn, tp = confusion_matrix(y_true=labels_all, y_pred=predictions).ravel()\n",
    "\n",
    "#print(f\"tn {tn}, fp {fp}, fn {fn}, tp {tp}\")\n",
    "\n",
    "# _ = ConfusionMatrixDisplay.from_estimator(classifier_05, X_test, y_test)\n",
    "\n",
    "#def get_label(x):\n",
    "#    return [classes[z] for z in x]\n",
    "\n",
    "#cm = confusion_matrix(y_true=get_label(labels_all), y_pred=get_label(y_d), labels=classes)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=classes)\n",
    "#disp.plot()\n",
    "#plt.show()\n",
    "\n",
    "accuracy = accuracy_score(labels_all, predictions)\n",
    "print(f\"Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "precision = precision_score(labels_all, predictions, average='macro') # macro oznacza średnią dla wszystkich kals\n",
    "print(f\"Precision = {precision:.4f}\")\n",
    "recall = recall_score(labels_all, predictions, average='macro')\n",
    "print(f\"Recall = {recall:.4f}\")\n",
    "f1 = f1_score(labels_all, predictions, average='macro')\n",
    "print(f\"F1 = {f1:.4f}\")\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(labels_all, predictions).ravel()\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(labels_all, predictions)\n",
    "print(class_report)\n",
    "\n",
    "roc_auc = roc_auc_score(\n",
    "    np.eye(10)[labels_all],  # One-hot encoding prawdziwych etykiet\n",
    "    outputs_all,             # Prawdopodobieństwa (logity po softmax)\n",
    "    multi_class='ovr'        # Podejście \"One-vs-Rest\"\n",
    ")\n",
    "\n",
    "print(f\"AUC = {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: cane  is 92.1 %\n",
      "Accuracy for class: cavallo is 91.2 %\n",
      "Accuracy for class: elefante is 90.6 %\n",
      "Accuracy for class: farfalla is 91.6 %\n",
      "Accuracy for class: gallina is 95.1 %\n",
      "Accuracy for class: gatto is 86.8 %\n",
      "Accuracy for class: mucca is 87.6 %\n",
      "Accuracy for class: pecora is 89.0 %\n",
      "Accuracy for class: ragno is 97.8 %\n",
      "Accuracy for class: scoiattolo is 88.3 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
