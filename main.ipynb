{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 300\n",
    "img_width = 200\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'spider', 'squirrel']\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Przykładowe wartości\n",
    "])\n",
    "\n",
    "data_dir = './raw-img-2'  # Path to your dataset\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "classes = dataset.classes\n",
    "\n",
    "print(classes)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_data, val_data= random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, batch_size, kernel_size=5, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        n_channels = self.feature_extractor(torch.empty(1, 3, img_height, img_width)).size(-1)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=n_channels, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=512, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=len(classes))\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "\n",
    "\n",
    "net = SimpleCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uczenie\n",
    "epochs = 20\n",
    "\n",
    "net.train()\n",
    "for epoch in range(epochs):\n",
    "    loss_epoch = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for i, batch in enumerate(train_loader, 0):\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_epoch += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "        # print(f\"epoch {epoch}, batch = {i}, loss = {loss.item()}, inputs.shape = {inputs.shape}\")\n",
    "    print(f\"epoch = {epoch}, accuracy = {accuracy}, loss = {loss_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapisz model\n",
    "\n",
    "torch.save(net.state_dict(), './neural-network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=52992, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# załaduj wytrenowany model\n",
    "\n",
    "net = SimpleCNN()\n",
    "net.load_state_dict(torch.load('./cnn_20_en_v2.pth', weights_only=True, map_location=torch.device('cpu')))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.2041084e-04 4.0947314e-02 1.0577036e-02 ... 8.4640384e-02\n",
      "  1.0081687e-03 1.5953753e-02]\n",
      " [4.8734903e-04 3.0005045e-02 1.9337343e-03 ... 2.0631100e-03\n",
      "  3.8184195e-03 1.6428629e-03]\n",
      " [9.9999952e-01 3.6359010e-11 4.1177906e-08 ... 2.1001870e-12\n",
      "  2.3953839e-07 5.0393441e-09]\n",
      " ...\n",
      " [1.9626400e-08 1.1850730e-08 9.2079899e-10 ... 2.7979638e-07\n",
      "  5.9896883e-09 7.3614865e-09]\n",
      " [5.6026998e-04 9.9043894e-01 9.5272332e-04 ... 3.7836097e-07\n",
      "  4.1101966e-04 6.2243671e-05]\n",
      " [2.9135012e-04 9.9608201e-01 2.3082037e-05 ... 5.0516970e-05\n",
      "  2.7990730e-03 7.2960298e-05]]\n",
      "[4 4 0 ... 6 1 1]\n",
      "(5236, 10)\n",
      "(5236,)\n"
     ]
    }
   ],
   "source": [
    "# testowanie\n",
    "net.eval()\n",
    "\n",
    "outputs_all = []\n",
    "labels_all = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images, labels = batch\n",
    "        outputs = net(images)\n",
    "        outputs_all.append(torch.softmax(outputs, dim=1).detach().cpu().numpy())\n",
    "        labels_all.append(labels.numpy())\n",
    "\n",
    "outputs_all = np.concatenate(outputs_all)\n",
    "labels_all = np.concatenate(labels_all)\n",
    "\n",
    "print(outputs_all)\n",
    "print(labels_all)\n",
    "\n",
    "print(outputs_all.shape)\n",
    "print(labels_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: cat\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image_path = './val_img/cat.jpg'\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():  # No gradient computation for inference\n",
    "    outputs = net(image_tensor)\n",
    "    _, predicted_class = torch.max(outputs, 1)  # Get the class index with the highest score\n",
    "\n",
    "\n",
    "predicted_label = classes[predicted_class.item()]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9886\n",
      "Accuracy = 0.9110\n",
      "Precision = 0.9150\n",
      "Recall = 0.8990\n",
      "F1 = 0.9066\n",
      "[392   1   3   0   3   0   1   1  25   2   2 269   1   1  25   0   0   0\n",
      "  15   4   5   1 557   0  10   0   2   2  10   6   3   2   0 319  16   4\n",
      "  14   6   1   0   2  21   4   8 859   4  10   9  21   5   1   0   1   3\n",
      "  16 267   6   2  11   1   2   3   5   7  13   6 512   3   2   1   1   1\n",
      "   1   9  16   2   5 319   6   2   7   5   3   0   7   3   1   4 932   8\n",
      "   3   5   7   2  15   3   1   1  15 344]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       428\n",
      "           1       0.87      0.85      0.86       317\n",
      "           2       0.96      0.94      0.95       593\n",
      "           3       0.91      0.87      0.89       365\n",
      "           4       0.88      0.91      0.89       943\n",
      "           5       0.92      0.87      0.89       308\n",
      "           6       0.93      0.92      0.93       554\n",
      "           7       0.92      0.88      0.90       362\n",
      "           8       0.90      0.96      0.93       970\n",
      "           9       0.92      0.87      0.89       396\n",
      "\n",
      "    accuracy                           0.91      5236\n",
      "   macro avg       0.91      0.90      0.91      5236\n",
      "weighted avg       0.91      0.91      0.91      5236\n",
      "\n",
      "AUC = 0.9886\n"
     ]
    }
   ],
   "source": [
    "\n",
    "AUC = roc_auc_score(np.eye(10)[labels_all], outputs_all, multi_class='ovo')\n",
    "print(f\"AUC = {AUC:.4f}\")\n",
    "\n",
    "#fpr, tpr, thresholds = roc_curve(y_true=labels_all, y_score=outputs_all, pos_label=1)\n",
    "#plt.plot(fpr, tpr)\n",
    "\n",
    "\n",
    "predictions = np.argmax(outputs_all, axis=1)\n",
    "#tn, fp, fn, tp = confusion_matrix(y_true=labels_all, y_pred=predictions).ravel()\n",
    "\n",
    "#print(f\"tn {tn}, fp {fp}, fn {fn}, tp {tp}\")\n",
    "\n",
    "# _ = ConfusionMatrixDisplay.from_estimator(classifier_05, X_test, y_test)\n",
    "\n",
    "#def get_label(x):\n",
    "#    return [classes[z] for z in x]\n",
    "\n",
    "#cm = confusion_matrix(y_true=get_label(labels_all), y_pred=get_label(y_d), labels=classes)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=classes)\n",
    "#disp.plot()\n",
    "#plt.show()\n",
    "\n",
    "accuracy = accuracy_score(labels_all, predictions)\n",
    "print(f\"Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "precision = precision_score(labels_all, predictions, average='macro') # macro oznacza średnią dla wszystkich kals\n",
    "print(f\"Precision = {precision:.4f}\")\n",
    "recall = recall_score(labels_all, predictions, average='macro')\n",
    "print(f\"Recall = {recall:.4f}\")\n",
    "f1 = f1_score(labels_all, predictions, average='macro')\n",
    "print(f\"F1 = {f1:.4f}\")\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(labels_all, predictions).ravel()\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(labels_all, predictions)\n",
    "print(class_report)\n",
    "\n",
    "roc_auc = roc_auc_score(\n",
    "    np.eye(len(classes))[labels_all],  # One-hot encoding prawdziwych etykiet\n",
    "    outputs_all,             # Prawdopodobieństwa (logity po softmax)\n",
    "    multi_class='ovr'        # Podejście \"One-vs-Rest\"\n",
    ")\n",
    "\n",
    "print(f\"AUC = {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: butterfly is 91.6 %\n",
      "Accuracy for class: cat   is 84.9 %\n",
      "Accuracy for class: chicken is 93.9 %\n",
      "Accuracy for class: cow   is 87.4 %\n",
      "Accuracy for class: dog   is 91.1 %\n",
      "Accuracy for class: elephant is 86.7 %\n",
      "Accuracy for class: horse is 92.4 %\n",
      "Accuracy for class: sheep is 88.1 %\n",
      "Accuracy for class: spider is 96.1 %\n",
      "Accuracy for class: squirrel is 86.9 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
